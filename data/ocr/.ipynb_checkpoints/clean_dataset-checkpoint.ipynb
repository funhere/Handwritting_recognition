{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Cleaning dataset for Phase2 After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "\n",
    "# Original dataset organisation.\n",
    "DIRECTORY_ANNOTATIONS_ORG = 'Annotations_org/'\n",
    "DIRECTORY_IMAGES_ORG = 'JPEGImages_org/'\n",
    "DIRECTORY_ANNOTATIONS = 'Annotations/'\n",
    "DIRECTORY_IMAGES = 'JPEGImages/'\n",
    "DIRECTORY_IMAGES = './Phase2-After-20180705/JPEGImages/'\n",
    "DIRECTORY_ANNOTATIONS = './Phase2-After-20180705/Annotations/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1479 2040\n"
     ]
    }
   ],
   "source": [
    "# Dataset filenames, and shuffling.\n",
    "path_xml = os.path.join(\"./Phase2-After-20180705\", DIRECTORY_ANNOTATIONS_ORG)\n",
    "filenames_xml = sorted(os.listdir(path_xml))\n",
    "\n",
    "path_img = os.path.join(\"./Phase2-After-20180705\", DIRECTORY_IMAGES_ORG)\n",
    "filenames_img = sorted(os.listdir(path_img))\n",
    "print(len(filenames_xml),len(filenames_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not tf.gfile.Exists(DIRECTORY_IMAGES):\n",
    "    tf.gfile.MakeDirs(DIRECTORY_IMAGES)\n",
    "if not tf.gfile.Exists(DIRECTORY_ANNOTATIONS):\n",
    "    tf.gfile.MakeDirs(DIRECTORY_ANNOTATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unexsited file name: .DS_S.jpg\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < len(filenames_xml):\n",
    "    filename_xml = filenames_xml[i][:-4] #file name without '.xml'\n",
    "    img_file = filename_xml + '.jpg'\n",
    "    if img_file in filenames_img:\n",
    "        cmd_str = 'cp ./Phase2-After-20180705/JPEGImages_org/'+img_file +' ' + DIRECTORY_IMAGES\n",
    "        os.system(cmd_str)   \n",
    "    else:\n",
    "        print(\"unexsited file name:\",img_file)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1.1 train,test dataset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cleaning dataset for Phase1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "\n",
    "# Original dataset organisation.\n",
    "DIRECTORY_ANNOTATIONS_ORG = './Phase1/Annotations_org/'\n",
    "DIRECTORY_IMAGES_ORG = './Phase1/JPEGImages_org/'\n",
    "DIRECTORY_ANNOTATIONS = './Phase1/Annotations/'\n",
    "DIRECTORY_IMAGES = './Phase1/JPEGImages/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2550 2612\n"
     ]
    }
   ],
   "source": [
    "# Dataset filenames, and shuffling.\n",
    "path_xml = os.path.join(DIRECTORY_ANNOTATIONS_ORG)\n",
    "filenames_xml = sorted(os.listdir(path_xml))\n",
    "\n",
    "path_img = os.path.join(DIRECTORY_IMAGES_ORG)\n",
    "filenames_img = sorted(os.listdir(path_img))\n",
    "print(len(filenames_xml),len(filenames_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not tf.gfile.Exists(DIRECTORY_IMAGES):\n",
    "    tf.gfile.MakeDirs(DIRECTORY_IMAGES)\n",
    "if not tf.gfile.Exists(DIRECTORY_ANNOTATIONS):\n",
    "    tf.gfile.MakeDirs(DIRECTORY_ANNOTATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(filenames_xml):\n",
    "    filename_xml = filenames_xml[i]\n",
    "    filename = filename_xml[:-4] #file name without '.xml'\n",
    "    img_file = filename + '.jpg'\n",
    "    if img_file in filenames_img:\n",
    "        cmd_cp_img = 'cp ' + DIRECTORY_IMAGES_ORG + img_file +' ' + DIRECTORY_IMAGES\n",
    "        os.system(cmd_cp_img) \n",
    "        cmd_cp_xml = 'cp ' + DIRECTORY_ANNOTATIONS_ORG + filename_xml +' ' + DIRECTORY_ANNOTATIONS\n",
    "        os.system(cmd_cp_xml)\n",
    "    else:\n",
    "        print(\"unexsited file name:\",img_file)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Shuffle and seperate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2550 2550\n"
     ]
    }
   ],
   "source": [
    "path_xml = os.path.join(DIRECTORY_ANNOTATIONS)\n",
    "ds_xml = sorted(os.listdir(path_xml))\n",
    "\n",
    "path_img = os.path.join(DIRECTORY_IMAGES)\n",
    "ds_img = sorted(os.listdir(path_img))\n",
    "print(len(ds_xml),len(ds_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LF00003176532_003.jpeg_71.xml',\n",
       " 'LF00003176534_000.jpeg_61.xml',\n",
       " 'LF00003176542_000.jpeg_55.xml',\n",
       " 'LF00003176568_000.jpeg_27.xml',\n",
       " 'LF00003176584_000.jpeg_38.xml',\n",
       " 'LF00003176588_000.jpeg_48.xml',\n",
       " 'LF00003176652_000.jpeg_73.xml',\n",
       " 'LF00003176658_001.jpeg_48.xml',\n",
       " 'LF00003176662_000.jpeg_49.xml',\n",
       " 'LF00003176666_000.jpeg_31.xml']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_xml[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratio=0.1\n",
    "test_size=int(len(ds_xml) * test_ratio)\n",
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 2295)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_xml=ds_xml[:test_size]\n",
    "train_xml=ds_xml[test_size:]\n",
    "len(test_xml),len(train_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['LF00003176532_003.jpeg_71.xml',\n",
       "  'LF00003176534_000.jpeg_61.xml',\n",
       "  'LF00003176542_000.jpeg_55.xml',\n",
       "  'LF00003176568_000.jpeg_27.xml',\n",
       "  'LF00003176584_000.jpeg_38.xml'],\n",
       " 'LF00003179070_000.jpeg_66.xml')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_xml[:5], test_xml[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 2295)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img=ds_img[:test_size]\n",
    "train_img=ds_img[test_size:]\n",
    "len(test_img),len(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['LF00003176532_003.jpeg_71.jpg',\n",
       "  'LF00003176534_000.jpeg_61.jpg',\n",
       "  'LF00003176542_000.jpeg_55.jpg',\n",
       "  'LF00003176568_000.jpeg_27.jpg',\n",
       "  'LF00003176584_000.jpeg_38.jpg'],\n",
       " 'LF00003179070_000.jpeg_66.jpg')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img[:5], test_img[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_dir = \"./Phase1/test/\"\n",
    "if not tf.gfile.Exists(mk_dir):\n",
    "    tf.gfile.MakeDirs(mk_dir)\n",
    "mk_dir = \"./Phase1/test/JPEGImages/\"\n",
    "if not tf.gfile.Exists(mk_dir):\n",
    "    tf.gfile.MakeDirs(mk_dir)\n",
    "mk_dir = \"./Phase1/test/Annotations/\"\n",
    "if not tf.gfile.Exists(mk_dir):\n",
    "    tf.gfile.MakeDirs(mk_dir)\n",
    "\n",
    "    \n",
    "mk_dir = \"./Phase1/train/\"\n",
    "if not tf.gfile.Exists(mk_dir):\n",
    "    tf.gfile.MakeDirs(mk_dir)\n",
    "mk_dir = \"./Phase1/train/JPEGImages/\"\n",
    "if not tf.gfile.Exists(mk_dir):\n",
    "    tf.gfile.MakeDirs(mk_dir)\n",
    "mk_dir = \"./Phase1/train/Annotations/\"\n",
    "if not tf.gfile.Exists(mk_dir):\n",
    "    tf.gfile.MakeDirs(mk_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy train dataset\n",
    "\"\"\"\n",
    "for itm in train_xml:\n",
    "    cmd = 'cp -rf ' + DIRECTORY_ANNOTATIONS + itm + ' ./Phase1/train/Annotations/'\n",
    "    os.system(cmd) \n",
    "\"\"\"    \n",
    "for itm in train_img:\n",
    "    cmd = 'cp -rf ' + DIRECTORY_IMAGES + itm + ' ./Phase1/train/JPEGImages/'\n",
    "    os.system(cmd)\n",
    "    \n",
    "# copy test dataset\n",
    "for itm in test_xml:\n",
    "    cmd = 'cp -rf ' + DIRECTORY_ANNOTATIONS + itm + ' ./Phase1/test/Annotations/'\n",
    "    os.system(cmd) \n",
    "    \n",
    "for itm in test_img:\n",
    "    cmd = 'cp -rf ' + DIRECTORY_IMAGES + itm + ' ./Phase1/test/JPEGImages/'\n",
    "    os.system(cmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
